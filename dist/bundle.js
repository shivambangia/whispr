/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./popup/popup.js":
/*!************************!*\
  !*** ./popup/popup.js ***!
  \************************/
/***/ (() => {

eval("// popup/popup.js\nwindow.onload = () => {\n    console.log(\"Popup script loaded.\");\n\n    const btn = document.getElementById('startBtn');\n    const output = document.getElementById('output');\n    const statusDiv = document.getElementById('status'); // Get status element\n\n    // Basic check for browser compatibility\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n        statusDiv.textContent = \"Speech Recognition API not supported in this browser.\";\n        console.error(\"SpeechRecognition not supported\");\n        btn.disabled = true;\n        return; // Stop execution if not supported\n    }\n\n    const recognition = new SpeechRecognition();\n    recognition.continuous = false; // Process speech after user stops talking\n    recognition.interimResults = false; // Only final results\n    recognition.lang = 'en-US'; // Set language\n\n    let isRecording = false;\n\n    btn.onclick = () => {\n        if (isRecording) {\n            recognition.stop(); // Stop recognition if already recording\n            // UI update handled in onend\n        } else {\n            console.log(\"Starting recognition...\");\n            output.value = \"\"; // Clear previous transcript\n            statusDiv.textContent = \"Listening...\";\n            btn.textContent = \"Stop Recording\";\n            btn.disabled = true; // Disable button briefly to prevent immediate stop\n            try {\n                recognition.start();\n                isRecording = true;\n                // Re-enable after a short delay allows start() to initiate\n                setTimeout(() => { btn.disabled = false; }, 500);\n            } catch (err) {\n                console.error(\"Error calling recognition.start():\", err);\n                statusDiv.textContent = \"Error starting recording: \" + err.message;\n                btn.textContent = \"Start Recording\";\n                btn.disabled = false;\n                isRecording = false;\n            }\n        }\n    };\n\n    recognition.onresult = (event) => {\n        const transcript = event.results[0][0].transcript;\n        console.log(\"Transcript received:\", transcript);\n        output.value = transcript; // Show transcript in textarea\n        statusDiv.textContent = \"Processing request...\"; // Update status\n        btn.disabled = true; // Disable button while processing\n\n        // Send the transcript to the background script for processing\n        chrome.runtime.sendMessage(\n            { type: \"PROCESS_TRANSCRIPT\", payload: transcript },\n            (response) => {\n                if (chrome.runtime.lastError) {\n                    // Handle errors like the background script not being ready\n                    console.error(\"Error sending message:\", chrome.runtime.lastError.message);\n                    statusDiv.textContent = \"Error: Could not contact background script.\";\n                    // Consider re-enabling the button here or providing specific feedback\n                } else if (response) {\n                    console.log(\"Received response from background:\", response);\n                    statusDiv.textContent = response.message || \"Processing complete.\"; // Update status with response\n                } else {\n                    // Handle cases where the background script didn't send a response\n                    // This might be normal depending on your background script's logic\n                    console.log(\"Background script did not send a response.\");\n                     statusDiv.textContent = \"Request sent, no confirmation received.\";\n                }\n                 // Re-enable the button once processing (or sending) is done/failed\n                btn.disabled = false;\n                btn.textContent = \"Start Recording\"; // Reset button text\n            }\n        );\n    };\n\n    recognition.onerror = (event) => {\n        console.error(\"Speech recognition error:\", event.error, event.message);\n        let errorMessage = 'Speech recognition error: ' + event.error;\n        if (event.error === 'no-speech') {\n            errorMessage = \"No speech detected. Please try again.\";\n        } else if (event.error === 'audio-capture') {\n            errorMessage = \"Audio capture error. Ensure microphone is enabled.\";\n        } else if (event.error === 'not-allowed') {\n            errorMessage = \"Microphone access denied. Please allow access.\";\n        }\n        statusDiv.textContent = errorMessage;\n        isRecording = false; // Ensure state is reset\n        btn.textContent = \"Start Recording\";\n        btn.disabled = false;\n    };\n\n    recognition.onend = () => {\n        console.log(\"Recognition ended.\");\n        isRecording = false;\n        // Don't reset button text/state here if onresult is expected\n        // If recognition ends without a result (e.g., timeout, manual stop without speech), reset UI\n        if (output.value === \"\") { // Check if a result was processed\n            btn.textContent = \"Start Recording\";\n            btn.disabled = false;\n            if(statusDiv.textContent === \"Listening...\") { // Avoid overwriting error messages\n               statusDiv.textContent = \"Click the button to start recording\";\n            }\n        }\n         // If it ends *after* processing, the onresult callback handles UI updates\n    };\n\n    // Optional: Listen for status updates from the background script\n    chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {\n        if (request.type === \"STATUS_UPDATE\") {\n            console.log(\"Received status update:\", request.payload);\n            statusDiv.textContent = request.payload;\n            // You could also re-enable/disable the button based on status if needed\n            // if(request.payload === \"Task Complete\" || request.payload.startsWith(\"Error:\")) {\n            //      btn.disabled = false;\n            //      btn.textContent = \"Start Recording\";\n            // }\n        }\n        // Keep the message channel open for asynchronous responses if needed\n        // return true;\n    });\n\n    // Initial status\n    statusDiv.textContent = \"Click the button to start recording\";\n\n}; // End window.onload\n\n//# sourceURL=webpack://whispr/./popup/popup.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = {};
/******/ 	__webpack_modules__["./popup/popup.js"]();
/******/ 	
/******/ })()
;