{"version":3,"file":"node_modules_langchain_dist_chains_api_api_chain_js.background.bundle.js","mappings":";;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACnHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://whispr/../../node_modules/langchain/dist/chains/api/api_chain.js","webpack://whispr/../../node_modules/langchain/dist/chains/api/prompts.js"],"sourcesContent":["import { BaseChain } from \"../base.js\";\nimport { LLMChain } from \"../llm_chain.js\";\nimport { API_URL_PROMPT_TEMPLATE, API_RESPONSE_PROMPT_TEMPLATE, } from \"./prompts.js\";\n/**\n * Class that extends BaseChain and represents a chain specifically\n * designed for making API requests and processing API responses.\n */\nexport class APIChain extends BaseChain {\n    get inputKeys() {\n        return [this.inputKey];\n    }\n    get outputKeys() {\n        return [this.outputKey];\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"apiAnswerChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"apiRequestChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"apiDocs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"headers\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: {}\n        });\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"question\"\n        });\n        Object.defineProperty(this, \"outputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"output\"\n        });\n        this.apiRequestChain = fields.apiRequestChain;\n        this.apiAnswerChain = fields.apiAnswerChain;\n        this.apiDocs = fields.apiDocs;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n        this.outputKey = fields.outputKey ?? this.outputKey;\n        this.headers = fields.headers ?? this.headers;\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        const question = values[this.inputKey];\n        const api_url = await this.apiRequestChain.predict({ question, api_docs: this.apiDocs }, runManager?.getChild(\"request\"));\n        const res = await fetch(api_url, { headers: this.headers });\n        const api_response = await res.text();\n        const answer = await this.apiAnswerChain.predict({ question, api_docs: this.apiDocs, api_url, api_response }, runManager?.getChild(\"response\"));\n        return { [this.outputKey]: answer };\n    }\n    _chainType() {\n        return \"api_chain\";\n    }\n    static async deserialize(data) {\n        const { api_request_chain, api_answer_chain, api_docs } = data;\n        if (!api_request_chain) {\n            throw new Error(\"LLMChain must have api_request_chain\");\n        }\n        if (!api_answer_chain) {\n            throw new Error(\"LLMChain must have api_answer_chain\");\n        }\n        if (!api_docs) {\n            throw new Error(\"LLMChain must have api_docs\");\n        }\n        return new APIChain({\n            apiAnswerChain: await LLMChain.deserialize(api_answer_chain),\n            apiRequestChain: await LLMChain.deserialize(api_request_chain),\n            apiDocs: api_docs,\n        });\n    }\n    serialize() {\n        return {\n            _type: this._chainType(),\n            api_answer_chain: this.apiAnswerChain.serialize(),\n            api_request_chain: this.apiRequestChain.serialize(),\n            api_docs: this.apiDocs,\n        };\n    }\n    /**\n     * Static method to create a new APIChain from a BaseLanguageModel and API\n     * documentation.\n     * @param llm BaseLanguageModel instance.\n     * @param apiDocs API documentation.\n     * @param options Optional configuration options for the APIChain.\n     * @returns New APIChain instance.\n     */\n    static fromLLMAndAPIDocs(llm, apiDocs, options = {}) {\n        const { apiUrlPrompt = API_URL_PROMPT_TEMPLATE, apiResponsePrompt = API_RESPONSE_PROMPT_TEMPLATE, } = options;\n        const apiRequestChain = new LLMChain({ prompt: apiUrlPrompt, llm });\n        const apiAnswerChain = new LLMChain({ prompt: apiResponsePrompt, llm });\n        return new this({\n            apiAnswerChain,\n            apiRequestChain,\n            apiDocs,\n            ...options,\n        });\n    }\n}\n","/* eslint-disable spaced-comment */\nimport { PromptTemplate } from \"@langchain/core/prompts\";\nexport const API_URL_RAW_PROMPT_TEMPLATE = `You are given the below API Documentation:\n{api_docs}\nUsing this documentation, generate the full API url to call for answering the user question.\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\n\nQuestion:{question}\nAPI url:`;\nexport const API_URL_PROMPT_TEMPLATE = /* #__PURE__ */ new PromptTemplate({\n    inputVariables: [\"api_docs\", \"question\"],\n    template: API_URL_RAW_PROMPT_TEMPLATE,\n});\nexport const API_RESPONSE_RAW_PROMPT_TEMPLATE = `${API_URL_RAW_PROMPT_TEMPLATE} {api_url}\n\nHere is the response from the API:\n\n{api_response}\n\nSummarize this response to answer the original question.\n\nSummary:`;\nexport const API_RESPONSE_PROMPT_TEMPLATE = /* #__PURE__ */ new PromptTemplate({\n    inputVariables: [\"api_docs\", \"question\", \"api_url\", \"api_response\"],\n    template: API_RESPONSE_RAW_PROMPT_TEMPLATE,\n});\n"],"names":[],"sourceRoot":""}